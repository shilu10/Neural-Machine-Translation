{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","gpuClass":"standard"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf \nimport tensorflow.keras as keras\nfrom tensorflow.keras.layers import GRU, LSTM, Dense, Input, Lambda\nimport os, io\nimport shutil \nimport tqdm \nimport math\nimport pathlib\nimport numpy as np \nimport matplotlib.pyplot as plt\nfrom typing import *\nimport unicodedata\nimport re","metadata":{"id":"93Cp2M0GD5lG","execution":{"iopub.status.busy":"2023-05-13T14:28:11.781639Z","iopub.execute_input":"2023-05-13T14:28:11.782093Z","iopub.status.idle":"2023-05-13T14:28:18.543131Z","shell.execute_reply.started":"2023-05-13T14:28:11.782057Z","shell.execute_reply":"2023-05-13T14:28:18.542168Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"SPANISH_DATASET_URL = 'http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip'","metadata":{"id":"Z8GF2qoUFnTw","execution":{"iopub.status.busy":"2023-05-13T14:28:18.545095Z","iopub.execute_input":"2023-05-13T14:28:18.545915Z","iopub.status.idle":"2023-05-13T14:28:18.550858Z","shell.execute_reply.started":"2023-05-13T14:28:18.545860Z","shell.execute_reply":"2023-05-13T14:28:18.549973Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Download the spanish dataset.\npath_to_zip = tf.keras.utils.get_file(\n      'spa-eng.zip',\n      origin=SPANISH_DATASET_URL,\n      extract=True\n    )","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oQOeA1CQD80u","outputId":"9ec6fa96-7876-46f6-914f-5f57f0e8d9e7","execution":{"iopub.status.busy":"2023-05-13T14:28:18.552280Z","iopub.execute_input":"2023-05-13T14:28:18.553029Z","iopub.status.idle":"2023-05-13T14:28:18.675383Z","shell.execute_reply.started":"2023-05-13T14:28:18.552995Z","shell.execute_reply":"2023-05-13T14:28:18.674534Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n2638744/2638744 [==============================] - 0s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\"\n#path_to_file = pathlib.Path(path_to_zip).parent/'spa-eng/spa.txt'\n","metadata":{"id":"TDsSYwQyD8MX","execution":{"iopub.status.busy":"2023-05-13T14:44:36.451924Z","iopub.execute_input":"2023-05-13T14:44:36.452609Z","iopub.status.idle":"2023-05-13T14:44:36.456851Z","shell.execute_reply.started":"2023-05-13T14:44:36.452569Z","shell.execute_reply":"2023-05-13T14:44:36.455815Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"#1. convert unicode files to ascii\ndef unicode_to_ascii(s): \n  \"\"\"\n    function, converts the unicode data into ascii.\n    Params: \n      s(dtype: str): input string\n    Return(dtype: ascii)\n  \"\"\"\n  return ''.join(c for c in unicodedata.normalize('NFD',s) if unicodedata.category(c)!='Mn')\n\ndef preprocess_sentence(w):\n  \"\"\"\n    this function, does a preprocessing of the string, like converted to ascii and \n      removing the whitespaces.. And also adds the start and end token to the start and\n      end of the string respectively.\n    Params:\n      w(dtype: str): string, what needed to be preprocessed.\n    Return(dtype: str)\n      returns the string, which is preprocessed\n  \"\"\"\n    w = unicode_to_ascii(w.lower().strip())\n    w = re.sub(r\"([.,!?¿])\", r\" \\1 \", w)\n    w = re.sub('\\s{2,}', ' ', w)\n\n    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n    w = w.strip()\n\n    w = '<start> ' + w + ' <end>'\n    return w","metadata":{"id":"D2_68gfiD8KV","execution":{"iopub.status.busy":"2023-05-13T14:44:36.845944Z","iopub.execute_input":"2023-05-13T14:44:36.846873Z","iopub.status.idle":"2023-05-13T14:44:36.855030Z","shell.execute_reply.started":"2023-05-13T14:44:36.846826Z","shell.execute_reply":"2023-05-13T14:44:36.853779Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"BMbwMBnt2hVF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_data(path: str) -> Tuple:\n  \"\"\"\n    this function, will read the text from the input path, using io, and seperate into the \n    context and target for the preprocessing.\n    Params:\n      path(type: str): Input path of the text data.\n\n    Return(type: (List, List))\n      returns the list of context and list of target resp.\n  \"\"\"\n    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n    word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines]\n  \n    context = np.array([context for target, context in word_pairs])\n    target = np.array([target for target, context in word_pairs])\n\n    return context, target","metadata":{"id":"-jW0ZdOLD8IF","execution":{"iopub.status.busy":"2023-05-13T14:44:37.781917Z","iopub.execute_input":"2023-05-13T14:44:37.782565Z","iopub.status.idle":"2023-05-13T14:44:37.789521Z","shell.execute_reply.started":"2023-05-13T14:44:37.782524Z","shell.execute_reply":"2023-05-13T14:44:37.788069Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"context_text, target_text = read_data(path_to_file)\ncontext_text.shape","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TvfHJp2TD7vG","outputId":"e9569eb8-b590-4697-8fba-aa4650ca19aa","execution":{"iopub.status.busy":"2023-05-13T14:44:38.511106Z","iopub.execute_input":"2023-05-13T14:44:38.511682Z","iopub.status.idle":"2023-05-13T14:44:45.344437Z","shell.execute_reply.started":"2023-05-13T14:44:38.511645Z","shell.execute_reply":"2023-05-13T14:44:45.343318Z"},"trusted":true},"execution_count":104,"outputs":[{"execution_count":104,"output_type":"execute_result","data":{"text/plain":"(118964,)"},"metadata":{}}]},{"cell_type":"code","source":"context_text[1]","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"tMzJqVC1F7KQ","outputId":"c094bc1a-25da-4834-cb8b-e77066dc9ed2","execution":{"iopub.status.busy":"2023-05-13T14:44:45.348338Z","iopub.execute_input":"2023-05-13T14:44:45.349241Z","iopub.status.idle":"2023-05-13T14:44:45.362162Z","shell.execute_reply.started":"2023-05-13T14:44:45.349204Z","shell.execute_reply":"2023-05-13T14:44:45.361051Z"},"trusted":true},"execution_count":105,"outputs":[{"execution_count":105,"output_type":"execute_result","data":{"text/plain":"'<start> vete . <end>'"},"metadata":{}}]},{"cell_type":"code","source":"target_text[1]","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"aHwAlueVF7Hp","outputId":"9d468f4f-fa29-428f-8d29-1acf6fa46863","execution":{"iopub.status.busy":"2023-05-13T14:44:45.364078Z","iopub.execute_input":"2023-05-13T14:44:45.364450Z","iopub.status.idle":"2023-05-13T14:44:45.379178Z","shell.execute_reply.started":"2023-05-13T14:44:45.364415Z","shell.execute_reply":"2023-05-13T14:44:45.378055Z"},"trusted":true},"execution_count":106,"outputs":[{"execution_count":106,"output_type":"execute_result","data":{"text/plain":"'<start> go . <end>'"},"metadata":{}}]},{"cell_type":"code","source":"def get_vectorized_value(text): \n  \"\"\"\n    this function used to get the vector value for the given text value.\n    Params:\n      text(type; np.ndarray): numpy array contains the context or target data(text).\n    Return(type: (tf.Tensor, tf.keras.Preprocessing))\n      returns the tensor(which is a ineger sequence for text data), and vectorized function.\n  \"\"\"\n    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n    lang_tokenizer.fit_on_texts(text)\n\n    text_tensor = lang_tokenizer.texts_to_sequences(text)\n\n    text_tensor = tf.keras.preprocessing.sequence.pad_sequences(text_tensor,\n                                                         padding='post')\n    return text_tensor, lang_tokenizer","metadata":{"id":"ObC0jYU9DSb3","execution":{"iopub.status.busy":"2023-05-13T14:44:45.384806Z","iopub.execute_input":"2023-05-13T14:44:45.387454Z","iopub.status.idle":"2023-05-13T14:44:45.405292Z","shell.execute_reply.started":"2023-05-13T14:44:45.387420Z","shell.execute_reply":"2023-05-13T14:44:45.404067Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"context_tensor, context_tokenizer = get_vectorized_value(context_text)\ntarget_tensor, target_tokenizer = get_vectorized_value(target_text)\ntarget_tensor.shape","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sfEiYGMFEh_f","outputId":"00da155a-0464-4c42-fd4d-7dc10d4438f9","execution":{"iopub.status.busy":"2023-05-13T14:44:45.410326Z","iopub.execute_input":"2023-05-13T14:44:45.416422Z","iopub.status.idle":"2023-05-13T14:44:52.778768Z","shell.execute_reply.started":"2023-05-13T14:44:45.416375Z","shell.execute_reply":"2023-05-13T14:44:52.777834Z"},"trusted":true},"execution_count":108,"outputs":[{"execution_count":108,"output_type":"execute_result","data":{"text/plain":"(118964, 51)"},"metadata":{}}]},{"cell_type":"code","source":"def split_dataset(context_data: np.array, target_data: np.array,\n                  is_test: bool, train_split: float, val_split: float,\n                  test_split=0.0) -> Tuple: \n  \"\"\"\n    this function, will create train, test and val data\n    Params:\n      is_test(dtype: Bool): used for does needed a test data or not.\n      train_split(dtype; float): Amount of training dataset.\n      test_split(dtype; float): Amount of testing dataset.\n      val_split(dtype; float): Amount of validation dataset.\n  \"\"\"\n    assert is_test and test_split > 0, \"You cannot create a testing split, by specifying is_test to False\"\n    assert train_split <= 1.0, 'Train Split value should be float, and should be lesser than 1.0'\n    assert val_split <= 1.0, 'val Split value should be float, and should be lesser than 1.0'\n    assert test_split <= 1.0, 'test Split value should be float, and should be lesser than 1.0'\n    assert train_split + test_split + val_split == 1.0, \"Sum of train, test and val split, does't add up to 1.0\"\n\n    len_data =  context_data.shape[0]\n    n_train = int(train_split * len_data)\n    n_val = int(val_split * len_data)\n\n    train_inds = np.random.choice(np.arange(len_data), n_train, replace=False)\n    val_inds = np.random.choice([i for i in np.arange(len_data) if i not in train_inds], n_val, replace=False)\n\n    if test_split: \n    \n        n_test = int(test_split * context_data.shape[0])\n        test_inds = [i for i in np.arange(len_data) if i not in train_inds and i not in val_inds]\n\n        return (context_data[train_inds], target_data[train_inds]), \\\n              (context_data[val_inds], target_data[val_inds]), \\\n          (context_data[test_inds], target_data[test_inds])\n\n    return (context_data[train_inds], target_data[train_inds]), (context_data[val_inds], target_data[val_inds])","metadata":{"id":"M8tx7SMjF7Ef","execution":{"iopub.status.busy":"2023-05-13T14:44:52.780122Z","iopub.execute_input":"2023-05-13T14:44:52.780733Z","iopub.status.idle":"2023-05-13T14:44:52.791762Z","shell.execute_reply.started":"2023-05-13T14:44:52.780692Z","shell.execute_reply":"2023-05-13T14:44:52.790776Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"train_data, val_data, test_data = split_dataset(context_tensor, target_tensor, True, 0.8, 0.1, 0.1)","metadata":{"id":"X1OvhevVMADz","execution":{"iopub.status.busy":"2023-05-13T14:44:52.794805Z","iopub.execute_input":"2023-05-13T14:44:52.795167Z","iopub.status.idle":"2023-05-13T14:45:03.964104Z","shell.execute_reply.started":"2023-05-13T14:44:52.795140Z","shell.execute_reply":"2023-05-13T14:45:03.963106Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"code","source":"train_data[0].shape","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i4QHV9YdL_6v","outputId":"282cd261-a895-41fd-879f-e9129d9890f6","execution":{"iopub.status.busy":"2023-05-13T14:45:03.965469Z","iopub.execute_input":"2023-05-13T14:45:03.965830Z","iopub.status.idle":"2023-05-13T14:45:03.974309Z","shell.execute_reply.started":"2023-05-13T14:45:03.965785Z","shell.execute_reply":"2023-05-13T14:45:03.973247Z"},"trusted":true},"execution_count":111,"outputs":[{"execution_count":111,"output_type":"execute_result","data":{"text/plain":"(95171, 53)"},"metadata":{}}]},{"cell_type":"code","source":"def create_tensorflow_dataset(data: tf.Tensor, batch_size: int) -> tf.data.Dataset: \n  \"\"\"\n    this function, will create a tensorflow dataset, which utilizes the gpu/tpu more than the numpy\n      array.\n    Params:\n      data(type: Tuple): It is a tuple of data(train_X, train_y)\n      batch_size(dtype: int): Number of batch.\n    Return(type: tf.data.Dataset)\n      returns the data, that is converted to tf.data.Dataset.\n  \"\"\" \n    tensorflow_dataset = tf.data.Dataset.from_tensor_slices(data)\n    tensorflow_dataset = (\n               tensorflow_dataset.shuffle(1024)\n              .batch(batch_size, drop_remainder=True)\n              .prefetch(tf.data.experimental.AUTOTUNE)\n            )\n  \n    return tensorflow_dataset","metadata":{"id":"roUmsDZoL_2h","execution":{"iopub.status.busy":"2023-05-13T14:45:03.976127Z","iopub.execute_input":"2023-05-13T14:45:03.976571Z","iopub.status.idle":"2023-05-13T14:45:03.986345Z","shell.execute_reply.started":"2023-05-13T14:45:03.976536Z","shell.execute_reply":"2023-05-13T14:45:03.985430Z"},"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"code","source":"train_ds = create_tensorflow_dataset(train_data, 64)\nval_ds = create_tensorflow_dataset(val_data, 64)\ntest_ds = create_tensorflow_dataset(test_data, 64)","metadata":{"id":"Ie5nF3jML_ww","execution":{"iopub.status.busy":"2023-05-13T14:45:03.990675Z","iopub.execute_input":"2023-05-13T14:45:03.990961Z","iopub.status.idle":"2023-05-13T14:45:04.012659Z","shell.execute_reply.started":"2023-05-13T14:45:03.990937Z","shell.execute_reply":"2023-05-13T14:45:04.011677Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"code","source":"train_ds","metadata":{"id":"EhHXBSozF6_l","colab":{"base_uri":"https://localhost:8080/"},"outputId":"59af8ad5-5d4e-4590-d348-abd3b14976dc","execution":{"iopub.status.busy":"2023-05-13T14:45:04.014103Z","iopub.execute_input":"2023-05-13T14:45:04.014639Z","iopub.status.idle":"2023-05-13T14:45:04.021368Z","shell.execute_reply.started":"2023-05-13T14:45:04.014605Z","shell.execute_reply":"2023-05-13T14:45:04.020387Z"},"trusted":true},"execution_count":114,"outputs":[{"execution_count":114,"output_type":"execute_result","data":{"text/plain":"<PrefetchDataset element_spec=(TensorSpec(shape=(64, 53), dtype=tf.int32, name=None), TensorSpec(shape=(64, 51), dtype=tf.int32, name=None))>"},"metadata":{}}]},{"cell_type":"code","source":"eg_in, eg_de = next(iter(train_ds))","metadata":{"id":"GvuZ6V6kRd_A","execution":{"iopub.status.busy":"2023-05-13T14:45:04.022822Z","iopub.execute_input":"2023-05-13T14:45:04.023444Z","iopub.status.idle":"2023-05-13T14:45:04.060437Z","shell.execute_reply.started":"2023-05-13T14:45:04.023409Z","shell.execute_reply":"2023-05-13T14:45:04.059662Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"code","source":"INPUT_VOCAB_SIZE = len(context_tokenizer.word_index) + 1\nTARGET_VOCAB_SIZE = len(target_tokenizer.word_index) + 1\nEMB_DIMS = 256 \nHIDDEN_DIMS = 1024\nINPUT_SEQ_SIZE = eg_in.shape[1] \nTARGET_SEQ_SIZE = eg_de.shape[1]","metadata":{"id":"hEK2uje_LngA","execution":{"iopub.status.busy":"2023-05-13T14:45:04.062052Z","iopub.execute_input":"2023-05-13T14:45:04.062409Z","iopub.status.idle":"2023-05-13T14:45:04.067799Z","shell.execute_reply.started":"2023-05-13T14:45:04.062365Z","shell.execute_reply":"2023-05-13T14:45:04.066749Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"class Encoder(tf.keras.Model):\n  \"\"\"\n    this class, is used as for constructing the encoder of type lstm.\n    Methods:\n      __init__: constructor.\n      call: used to pass the input to get an output.\n      initialize_hidden_state: used to initialize the initial hidden state of encoder(h0).\n    Params:\n      vocab_size(dtype: int) Dimension of the vectorized input.\n      embedding_dim(dtype: int): number of hidden units in the embedding layer.\n      h;idden_units(dtype: int): Number of hidden units in the LSTM layer.\n      bt_size(dtype: int): Batch Size.\n  \"\"\"\n      def __init__(self, vocab_size: int, embedding_dim: int, hidden_units: int, bt_size: int):\n        super(Encoder, self).__init__()\n        self.bt_size = bt_size\n        self.hidden_units = hidden_units\n        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim, name=\"embedding_layr\")\n        self.rnn = tf.keras.layers.GRU(self.hidden_units,\n                                       return_sequences=True, \n                                       return_state=True, \n                                       recurrent_initializer='glorot_uniform',\n                                       name=\"lstm_layer\"\n                                      )\n\n    def call(self, x, hidden):\n        x = self.embedding(x)\n        output, state = self.rnn(x, hidden)\n        return output, state\n\n    def initialize_hidden_state(self):\n        return tf.zeros((self.bt_size, 1024))","metadata":{"id":"_nNhSFuFRd2q","execution":{"iopub.status.busy":"2023-05-13T14:45:04.069500Z","iopub.execute_input":"2023-05-13T14:45:04.069902Z","iopub.status.idle":"2023-05-13T14:45:04.082375Z","shell.execute_reply.started":"2023-05-13T14:45:04.069852Z","shell.execute_reply":"2023-05-13T14:45:04.081360Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"code","source":"lstm_encoder = Encoder(INPUT_VOCAB_SIZE, EMB_DIMS, HIDDEN_DIMS, 64)","metadata":{"id":"GMVUi9DARdtf","execution":{"iopub.status.busy":"2023-05-13T14:45:04.084283Z","iopub.execute_input":"2023-05-13T14:45:04.084807Z","iopub.status.idle":"2023-05-13T14:45:04.104374Z","shell.execute_reply.started":"2023-05-13T14:45:04.084771Z","shell.execute_reply":"2023-05-13T14:45:04.103405Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"code","source":"sample_hidden = lstm_encoder.initialize_hidden_state()\nsample_output, sample_hidden_ = lstm_encoder(eg_in, sample_hidden)\nprint ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\nprint ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ozbkD5f1GPG3","outputId":"a33ae162-2c46-4ece-9c8e-5e5cfb651211","execution":{"iopub.status.busy":"2023-05-13T14:45:04.105931Z","iopub.execute_input":"2023-05-13T14:45:04.106336Z","iopub.status.idle":"2023-05-13T14:45:04.128756Z","shell.execute_reply.started":"2023-05-13T14:45:04.106304Z","shell.execute_reply":"2023-05-13T14:45:04.127822Z"},"trusted":true},"execution_count":119,"outputs":[{"name":"stdout","text":"Encoder output shape: (batch size, sequence length, units) (64, 53, 1024)\nEncoder Hidden state shape: (batch size, units) (64, 1024)\n","output_type":"stream"}]},{"cell_type":"code","source":"class Decoder(tf.keras.Model):\n    def __init__(self, vocab_size, embedding_dim, hidden_units, bt_size):\n        \"\"\"\n          this class, is used as for constructing the decoder of type lstm.\n          Methods:\n            __init__: constructor.\n            call: used to pass the input to get an output.\n            initialize_hidden_state: used to initialize the initial hidden state of encoder(h0).\n          Params:\n            vocab_size(dtype: int) Dimension of the vectorized input.\n            embedding_dim(dtype: int): number of hidden units in the embedding layer.\n            h;idden_units(dtype: int): Number of hidden units in the LSTM layer.\n            bt_size(dtype: int): Batch Size.\n      \"\"\"\n        super(Decoder, self).__init__()\n        self.bt_size = bt_size\n        self.hidden_units = hidden_units\n        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim, name=\"embedding_layr\")\n        self.rnn = tf.keras.layers.GRU(self.hidden_units,\n                                       return_sequences=True,\n                                       return_state=True,\n                                       recurrent_initializer='glorot_uniform')\n        self.fc = tf.keras.layers.Dense(vocab_size)\n\n\n    def call(self, x, hidden_state):\n        x = self.embedding(x)\n        output, state = self.rnn(x, initial_state = hidden_state)\n        output = tf.reshape(output, (-1, output.shape[2]))\n\n        x = self.fc(output)\n        return x, state","metadata":{"id":"pOpmB_r0GO3_","execution":{"iopub.status.busy":"2023-05-13T14:45:04.130232Z","iopub.execute_input":"2023-05-13T14:45:04.130938Z","iopub.status.idle":"2023-05-13T14:45:04.139978Z","shell.execute_reply.started":"2023-05-13T14:45:04.130903Z","shell.execute_reply":"2023-05-13T14:45:04.138991Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"code","source":"lstm_decoder = Decoder(TARGET_VOCAB_SIZE, EMB_DIMS, HIDDEN_DIMS, 64)","metadata":{"id":"7Do82VF1LLC5","execution":{"iopub.status.busy":"2023-05-13T14:45:04.141367Z","iopub.execute_input":"2023-05-13T14:45:04.141922Z","iopub.status.idle":"2023-05-13T14:45:04.162415Z","shell.execute_reply.started":"2023-05-13T14:45:04.141790Z","shell.execute_reply":"2023-05-13T14:45:04.161441Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"code","source":"sample_decoder_output, _ = lstm_decoder(tf.random.uniform((64, 1)), sample_hidden)","metadata":{"id":"mm8r2xM7LK33","execution":{"iopub.status.busy":"2023-05-13T14:45:04.164038Z","iopub.execute_input":"2023-05-13T14:45:04.164468Z","iopub.status.idle":"2023-05-13T14:45:04.188442Z","shell.execute_reply.started":"2023-05-13T14:45:04.164433Z","shell.execute_reply":"2023-05-13T14:45:04.187565Z"},"trusted":true},"execution_count":122,"outputs":[]},{"cell_type":"code","source":"sample_decoder_output.shape","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zpylg_kGLKuE","outputId":"0c637368-d3bd-4b80-87d1-65f8954e0f57","execution":{"iopub.status.busy":"2023-05-13T14:45:04.189738Z","iopub.execute_input":"2023-05-13T14:45:04.190176Z","iopub.status.idle":"2023-05-13T14:45:04.196983Z","shell.execute_reply.started":"2023-05-13T14:45:04.190140Z","shell.execute_reply":"2023-05-13T14:45:04.195980Z"},"trusted":true},"execution_count":123,"outputs":[{"execution_count":123,"output_type":"execute_result","data":{"text/plain":"TensorShape([64, 12934])"},"metadata":{}}]},{"cell_type":"code","source":"dec_input = tf.expand_dims([target_tokenizer.word_index['<start>']] * 64, 1)","metadata":{"id":"u4cTemiYLKlt","execution":{"iopub.status.busy":"2023-05-13T14:28:49.616953Z","iopub.execute_input":"2023-05-13T14:28:49.617582Z","iopub.status.idle":"2023-05-13T14:28:49.628234Z","shell.execute_reply.started":"2023-05-13T14:28:49.617548Z","shell.execute_reply":"2023-05-13T14:28:49.627359Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"optimizer = tf.keras.optimizers.Adam()\n\ndef train_step(inp, targ, encoder,\n                       decoder, input_tok, target_tok, batch_size):\n    loss = 0\n    enc_hidden = encoder.initialize_hidden_state()\n    with tf.GradientTape() as tape: \n        enc_output, enc_hidden = encoder(inp, enc_hidden)\n        dec_hidden = enc_hidden\n        dec_input = tf.expand_dims([target_tok.word_index[\"<start>\"]] * batch_size, 1)\n\n        for t in range(1, targ.shape[1]):\n            predictions, dec_hidden = decoder(dec_input, dec_hidden)\n\n            loss += loss_function(targ[:, t], predictions)\n\n            dec_input = tf.expand_dims(targ[:, t], 1)\n\n    batch_loss = (loss / int(targ.shape[1]))\n    variables = encoder.trainable_variables + decoder.trainable_variables\n    gradients = tape.gradient(loss, variables)\n    optimizer.apply_gradients(zip(gradients, variables))\n    return batch_loss\n\n\ndef test_step(inp, targ, encoder,\n                      decoder, input_tok, target_tok, batch_size):\n    enc_hidden = encoder.initialize_hidden_state()\n    loss = 0\n    enc_output, enc_hidden = encoder(inp, enc_hidden)\n    dec_hidden = enc_hidden\n    dec_input = tf.expand_dims([target_tok.word_index[\"<start>\"]] * batch_size, 1)\n\n    for t in range(1, targ.shape[1]):\n        predictions, dec_hidden = decoder(dec_input, dec_hidden)\n        loss += loss_function(targ[:, t], predictions)\n        dec_input = tf.expand_dims(targ[:, t], 1)\n\n    loss = loss / int(targ.shape[1])\n    return loss","metadata":{"id":"zVgJ3wogUwdq","execution":{"iopub.status.busy":"2023-05-13T16:06:25.383867Z","iopub.execute_input":"2023-05-13T16:06:25.384345Z","iopub.status.idle":"2023-05-13T16:06:25.404799Z","shell.execute_reply.started":"2023-05-13T16:06:25.384307Z","shell.execute_reply":"2023-05-13T16:06:25.403748Z"},"trusted":true},"execution_count":188,"outputs":[]},{"cell_type":"code","source":"loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n\ndef loss_function(real, pred):\n    mask = tf.math.logical_not(tf.math.equal(real, 0)) \n    loss_ = loss_object(real, pred)\n    mask = tf.cast(mask, dtype=loss_.dtype)\n    loss_ *= mask\n    return tf.reduce_mean(loss_)","metadata":{"id":"_zQc_3SLUwEQ","execution":{"iopub.status.busy":"2023-05-13T16:06:25.742516Z","iopub.execute_input":"2023-05-13T16:06:25.745196Z","iopub.status.idle":"2023-05-13T16:06:25.753118Z","shell.execute_reply.started":"2023-05-13T16:06:25.745151Z","shell.execute_reply":"2023-05-13T16:06:25.752084Z"},"trusted":true},"execution_count":189,"outputs":[]},{"cell_type":"code","source":"import time\ndef training_seq2seq(encoder, decoder, train_dataset,\n                         val_dataset, input_tok, target_tok, epochs, batch_size):\n    training_loss = []\n    validation_loss = []\n\n    for epoch in range(epochs):\n        start = time.time()\n        total_loss = 0\n        total_loss_val =- 0\n\n        for (batch, (inp, targ)) in enumerate(tqdm.tqdm(train_dataset)):\n            batch_loss = train_step(inp, targ, \n                                    encoder, decoder, input_tok, target_tok, batch_size)\n\n            total_loss += batch_loss\n\n        for (batch, (inp, targ)) in enumerate((val_dataset)):\n            batch_loss = test_step(inp, targ,\n                                     encoder, decoder, input_tok, target_tok, batch_size)\n\n            total_loss_val += batch_loss\n\n        print(f\"Epoch {epoch} train_loss: {total_loss} val_loss: {total_loss_val}\")\n        \n\n    return encoder, decoder, training_loss, validation_loss","metadata":{"id":"WZRPZ2BjY1_X","execution":{"iopub.status.busy":"2023-05-13T16:06:26.191956Z","iopub.execute_input":"2023-05-13T16:06:26.192322Z","iopub.status.idle":"2023-05-13T16:06:26.200224Z","shell.execute_reply.started":"2023-05-13T16:06:26.192291Z","shell.execute_reply":"2023-05-13T16:06:26.199064Z"},"trusted":true},"execution_count":190,"outputs":[]},{"cell_type":"code","source":"encoder = Encoder(INPUT_VOCAB_SIZE, EMB_DIMS, HIDDEN_DIMS, 64)\ndecoder = Decoder(TARGET_VOCAB_SIZE, EMB_DIMS, HIDDEN_DIMS, 64)\nencoder_t, decoder_t, training_loss, validation_loss = training_seq2seq(encoder, decoder, \n                            train_ds, val_ds, context_tokenizer, target_tokenizer, 10, 64)\n\nencoder_t.save(\"seq_seq_gru_encoder\")\ndecoder_t.save(\"seq_seq_gru_decoder\")\n#https://cnvrg.io/seq2seq-model/","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":435},"id":"TSZGtSvZY1kg","outputId":"809c32c8-7227-498d-f25c-5832f2fa0a3e","execution":{"iopub.status.busy":"2023-05-13T16:06:26.731732Z","iopub.execute_input":"2023-05-13T16:06:26.732411Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":" 15%|█▌        | 230/1487 [03:22<17:07,  1.22it/s]","output_type":"stream"}]},{"cell_type":"code","source":"def translate(sentence, encoder, decoder):\n    attention_plot = np.zeros((51, 53))\n\n    sentence = preprocess_sentence(sentence)\n\n    inputs = [context_tokenizer.word_index[i] for i in sentence.split(' ')]\n    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n                                                         maxlen=51,\n                                                         padding='post')\n    inputs = tf.convert_to_tensor(inputs)\n\n    result = ''\n\n    hidden = [tf.zeros((1, 1024))]\n    enc_out, enc_hidden = encoder(inputs, hidden)\n\n    dec_hidden = enc_hidden\n    dec_input = tf.expand_dims([target_tokenizer.word_index['<start>']], 0)\n\n    for t in range(51):\n        predictions, dec_hidden = decoder(dec_input, dec_hidden)\n\n        predicted_id = tf.argmax(predictions[0]).numpy()\n\n        result += target_tokenizer.index_word[predicted_id] + ' '\n\n        if target_tokenizer.index_word[predicted_id] == '':\n            return result, sentence\n        dec_input = tf.expand_dims([predicted_id], 0)\n\n    return result, sentence\n     ","metadata":{"id":"8_2GKIynUvRl","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"translate(u'¿todavia estan en casa?', encoder, decoder)","metadata":{"id":"e2vB0jMdUu2V","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"y8z0sqmLUueD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder_inputs = Input(shape=(None,))\nen_x=  keras.layers.Embedding(INPUT_VOCAB_SIZE, 256)(encoder_inputs)\nencoder = LSTM(50, return_state=True)\nencoder_outputs, state_h, state_c = encoder(en_x)\n# We discard `encoder_outputs` and only keep the states.\nencoder_states = [state_h, state_c]\n\ndecoder_inputs = Input(shape=(None,))\ndex=  keras.layers.Embedding(TARGET_VOCAB_SIZE, 256)\nfinal_dex= dex(decoder_inputs)\n\ndecoder_lstm = LSTM(50, return_sequences=True, return_state=True)\ndecoder_outputs, _, _ = decoder_lstm(final_dex, initial_state=encoder_states)\ndecoder_dense = Dense(TARGET_VOCAB_SIZE, activation='softmax')\ndecoder_outputs = decoder_dense(decoder_outputs)","metadata":{"execution":{"iopub.status.busy":"2023-05-13T16:04:07.502051Z","iopub.execute_input":"2023-05-13T16:04:07.502439Z","iopub.status.idle":"2023-05-13T16:04:08.062393Z","shell.execute_reply.started":"2023-05-13T16:04:07.502406Z","shell.execute_reply":"2023-05-13T16:04:08.061398Z"},"trusted":true},"execution_count":185,"outputs":[]},{"cell_type":"code","source":"model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-13T16:04:29.471557Z","iopub.execute_input":"2023-05-13T16:04:29.471936Z","iopub.status.idle":"2023-05-13T16:04:29.481255Z","shell.execute_reply.started":"2023-05-13T16:04:29.471901Z","shell.execute_reply":"2023-05-13T16:04:29.480306Z"},"trusted":true},"execution_count":186,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer= ‘adam’, loss='categorical_crossentropy', metrics=['acc'])\n\nmodel.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n         batch_size=128,\n         epochs=10,\n         validation_split=0.05)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
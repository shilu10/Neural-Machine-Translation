{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","gpuClass":"standard"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf \nimport tensorflow.keras as keras\nfrom tensorflow.keras.layers import GRU, LSTM, Dense, Input, Lambda\nimport os, io\nimport shutil \nimport tqdm \nimport math\nimport pathlib\nimport numpy as np \nimport matplotlib.pyplot as plt\nfrom typing import *\nimport unicodedata\nimport re","metadata":{"id":"93Cp2M0GD5lG","execution":{"iopub.status.busy":"2023-05-15T00:09:06.728043Z","iopub.execute_input":"2023-05-15T00:09:06.728760Z","iopub.status.idle":"2023-05-15T00:09:06.737458Z","shell.execute_reply.started":"2023-05-15T00:09:06.728728Z","shell.execute_reply":"2023-05-15T00:09:06.736446Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"SPANISH_DATASET_URL = 'http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip'","metadata":{"id":"Z8GF2qoUFnTw","execution":{"iopub.status.busy":"2023-05-15T00:09:07.137206Z","iopub.execute_input":"2023-05-15T00:09:07.137543Z","iopub.status.idle":"2023-05-15T00:09:07.141823Z","shell.execute_reply.started":"2023-05-15T00:09:07.137518Z","shell.execute_reply":"2023-05-15T00:09:07.140845Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Download the spanish dataset.\npath_to_zip = tf.keras.utils.get_file(\n      'spa-eng.zip',\n      origin=SPANISH_DATASET_URL,\n      extract=True\n    )","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oQOeA1CQD80u","outputId":"9ec6fa96-7876-46f6-914f-5f57f0e8d9e7","execution":{"iopub.status.busy":"2023-05-15T00:09:07.777077Z","iopub.execute_input":"2023-05-15T00:09:07.777454Z","iopub.status.idle":"2023-05-15T00:09:08.648282Z","shell.execute_reply.started":"2023-05-15T00:09:07.777426Z","shell.execute_reply":"2023-05-15T00:09:08.647414Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n2638744/2638744 [==============================] - 1s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\"\n#path_to_file = pathlib.Path(path_to_zip).parent/'spa-eng/spa.txt'\n","metadata":{"id":"TDsSYwQyD8MX","execution":{"iopub.status.busy":"2023-05-15T00:09:08.650028Z","iopub.execute_input":"2023-05-15T00:09:08.650481Z","iopub.status.idle":"2023-05-15T00:09:08.655353Z","shell.execute_reply.started":"2023-05-15T00:09:08.650446Z","shell.execute_reply":"2023-05-15T00:09:08.654361Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#1. convert unicode files to ascii\ndef unicode_to_ascii(s): \n  \"\"\"\n    function, converts the unicode data into ascii.\n    Params: \n      s(dtype: str): input string\n    Return(dtype: ascii)\n  \"\"\"\n  return ''.join(c for c in unicodedata.normalize('NFD',s) if unicodedata.category(c)!='Mn')\n\ndef preprocess_sentence(w):\n    \"\"\"\n        this function, does a preprocessing of the string, like converted to ascii and \n          removing the whitespaces.. And also adds the start and end token to the start and\n          end of the string respectively.\n        Params:\n          w(dtype: str): string, what needed to be preprocessed.\n        Return(dtype: str)\n          returns the string, which is preprocessed\n    \"\"\"\n    w = unicode_to_ascii(w.lower().strip())\n    w = re.sub(r\"([.,!?¿])\", r\" \\1 \", w)\n    w = re.sub('\\s{2,}', ' ', w)\n\n    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n    w = w.strip()\n\n    w = '<start> ' + w + ' <end>'\n    return w","metadata":{"id":"D2_68gfiD8KV","execution":{"iopub.status.busy":"2023-05-15T00:09:09.117398Z","iopub.execute_input":"2023-05-15T00:09:09.117751Z","iopub.status.idle":"2023-05-15T00:09:09.124896Z","shell.execute_reply.started":"2023-05-15T00:09:09.117726Z","shell.execute_reply":"2023-05-15T00:09:09.123932Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"BMbwMBnt2hVF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_data(path: str) -> Tuple:\n    \"\"\"\n        this function, will read the text from the input path, using io, and seperate into the \n        context and target for the preprocessing.\n        Params:\n          path(type: str): Input path of the text data.\n\n        Return(type: (List, List))\n          returns the list of context and list of target resp.\n    \"\"\"\n    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n    word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines]\n  \n    context = np.array([context for target, context in word_pairs])\n    target = np.array([target for target, context in word_pairs])\n\n    return context, target","metadata":{"id":"-jW0ZdOLD8IF","execution":{"iopub.status.busy":"2023-05-15T00:09:10.447115Z","iopub.execute_input":"2023-05-15T00:09:10.448049Z","iopub.status.idle":"2023-05-15T00:09:10.455560Z","shell.execute_reply.started":"2023-05-15T00:09:10.448016Z","shell.execute_reply":"2023-05-15T00:09:10.454665Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"context_text, target_text = read_data(path_to_file)\ncontext_text.shape","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TvfHJp2TD7vG","outputId":"e9569eb8-b590-4697-8fba-aa4650ca19aa","execution":{"iopub.status.busy":"2023-05-15T00:09:11.197168Z","iopub.execute_input":"2023-05-15T00:09:11.197813Z","iopub.status.idle":"2023-05-15T00:09:17.791164Z","shell.execute_reply.started":"2023-05-15T00:09:11.197781Z","shell.execute_reply":"2023-05-15T00:09:17.790112Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(118964,)"},"metadata":{}}]},{"cell_type":"code","source":"context_text[1]","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"tMzJqVC1F7KQ","outputId":"c094bc1a-25da-4834-cb8b-e77066dc9ed2","execution":{"iopub.status.busy":"2023-05-15T00:09:17.793204Z","iopub.execute_input":"2023-05-15T00:09:17.793575Z","iopub.status.idle":"2023-05-15T00:09:17.800275Z","shell.execute_reply.started":"2023-05-15T00:09:17.793543Z","shell.execute_reply":"2023-05-15T00:09:17.799428Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"'<start> vete . <end>'"},"metadata":{}}]},{"cell_type":"code","source":"target_text[1]","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"aHwAlueVF7Hp","outputId":"9d468f4f-fa29-428f-8d29-1acf6fa46863","execution":{"iopub.status.busy":"2023-05-15T00:09:17.801866Z","iopub.execute_input":"2023-05-15T00:09:17.802552Z","iopub.status.idle":"2023-05-15T00:09:17.809854Z","shell.execute_reply.started":"2023-05-15T00:09:17.802519Z","shell.execute_reply":"2023-05-15T00:09:17.808863Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"'<start> go . <end>'"},"metadata":{}}]},{"cell_type":"code","source":"def get_vectorized_value(text): \n    \"\"\"\n        this function used to get the vector value for the given text value.\n        Params:\n          text(type; np.ndarray): numpy array contains the context or target data(text).\n        Return(type: (tf.Tensor, tf.keras.Preprocessing))\n          returns the tensor(which is a ineger sequence for text data), and vectorized function.\n    \"\"\"\n    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n    lang_tokenizer.fit_on_texts(text)\n\n    text_tensor = lang_tokenizer.texts_to_sequences(text)\n\n    text_tensor = tf.keras.preprocessing.sequence.pad_sequences(text_tensor,\n                                                         padding='post')\n    return text_tensor, lang_tokenizer","metadata":{"id":"ObC0jYU9DSb3","execution":{"iopub.status.busy":"2023-05-15T00:09:17.812058Z","iopub.execute_input":"2023-05-15T00:09:17.812781Z","iopub.status.idle":"2023-05-15T00:09:17.819159Z","shell.execute_reply.started":"2023-05-15T00:09:17.812749Z","shell.execute_reply":"2023-05-15T00:09:17.818318Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"context_tensor, context_tokenizer = get_vectorized_value(context_text)\ntarget_tensor, target_tokenizer = get_vectorized_value(target_text)\ntarget_tensor.shape","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sfEiYGMFEh_f","outputId":"00da155a-0464-4c42-fd4d-7dc10d4438f9","execution":{"iopub.status.busy":"2023-05-15T00:09:17.820562Z","iopub.execute_input":"2023-05-15T00:09:17.821059Z","iopub.status.idle":"2023-05-15T00:09:25.380833Z","shell.execute_reply.started":"2023-05-15T00:09:17.821029Z","shell.execute_reply":"2023-05-15T00:09:25.379876Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(118964, 51)"},"metadata":{}}]},{"cell_type":"code","source":"def split_dataset(context_data: np.array, target_data: np.array,\n                  is_test: bool, train_split: float, val_split: float,\n                  test_split=0.0) -> Tuple: \n    \"\"\"\n        this function, will create train, test and val data\n        Params:\n          is_test(dtype: Bool): used for does needed a test data or not.\n          train_split(dtype; float): Amount of training dataset.\n          test_split(dtype; float): Amount of testing dataset.\n          val_split(dtype; float): Amount of validation dataset.\n    \"\"\"\n    assert is_test and test_split > 0, \"You cannot create a testing split, by specifying is_test to False\"\n    assert train_split <= 1.0, 'Train Split value should be float, and should be lesser than 1.0'\n    assert val_split <= 1.0, 'val Split value should be float, and should be lesser than 1.0'\n    assert test_split <= 1.0, 'test Split value should be float, and should be lesser than 1.0'\n    assert train_split + test_split + val_split == 1.0, \"Sum of train, test and val split, does't add up to 1.0\"\n\n    len_data =  context_data.shape[0]\n    n_train = int(train_split * len_data)\n    n_val = int(val_split * len_data)\n\n    train_inds = np.random.choice(np.arange(len_data), n_train, replace=False)\n    val_inds = np.random.choice([i for i in np.arange(len_data) if i not in train_inds], n_val, replace=False)\n\n    if test_split: \n    \n        n_test = int(test_split * context_data.shape[0])\n        test_inds = [i for i in np.arange(len_data) if i not in train_inds and i not in val_inds]\n\n        return (context_data[train_inds], target_data[train_inds]), \\\n              (context_data[val_inds], target_data[val_inds]), \\\n          (context_data[test_inds], target_data[test_inds])\n\n    return (context_data[train_inds], target_data[train_inds]), (context_data[val_inds], target_data[val_inds])","metadata":{"id":"M8tx7SMjF7Ef","execution":{"iopub.status.busy":"2023-05-15T00:09:25.383937Z","iopub.execute_input":"2023-05-15T00:09:25.384226Z","iopub.status.idle":"2023-05-15T00:09:25.395175Z","shell.execute_reply.started":"2023-05-15T00:09:25.384203Z","shell.execute_reply":"2023-05-15T00:09:25.394310Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_data, val_data, test_data = split_dataset(context_tensor, target_tensor, True, 0.8, 0.1, 0.1)","metadata":{"id":"X1OvhevVMADz","execution":{"iopub.status.busy":"2023-05-15T00:09:25.396433Z","iopub.execute_input":"2023-05-15T00:09:25.396832Z","iopub.status.idle":"2023-05-15T00:09:35.952524Z","shell.execute_reply.started":"2023-05-15T00:09:25.396801Z","shell.execute_reply":"2023-05-15T00:09:35.951554Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_data[0].shape","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i4QHV9YdL_6v","outputId":"282cd261-a895-41fd-879f-e9129d9890f6","execution":{"iopub.status.busy":"2023-05-15T00:09:35.954092Z","iopub.execute_input":"2023-05-15T00:09:35.954466Z","iopub.status.idle":"2023-05-15T00:09:35.960576Z","shell.execute_reply.started":"2023-05-15T00:09:35.954434Z","shell.execute_reply":"2023-05-15T00:09:35.959728Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"(95171, 53)"},"metadata":{}}]},{"cell_type":"code","source":"def create_tensorflow_dataset(data: tf.Tensor, batch_size: int) -> tf.data.Dataset: \n    \"\"\"\n        this function, will create a tensorflow dataset, which utilizes the gpu/tpu more than the numpy\n          array.\n        Params:\n          data(type: Tuple): It is a tuple of data(train_X, train_y)\n          batch_size(dtype: int): Number of batch.\n        Return(type: tf.data.Dataset)\n          returns the data, that is converted to tf.data.Dataset.\n    \"\"\" \n    tensorflow_dataset = tf.data.Dataset.from_tensor_slices(data)\n    tensorflow_dataset = (\n               tensorflow_dataset.shuffle(1024)\n              .batch(batch_size, drop_remainder=True)\n              .prefetch(tf.data.experimental.AUTOTUNE)\n            )\n  \n    return tensorflow_dataset","metadata":{"id":"roUmsDZoL_2h","execution":{"iopub.status.busy":"2023-05-15T00:09:35.963225Z","iopub.execute_input":"2023-05-15T00:09:35.963848Z","iopub.status.idle":"2023-05-15T00:09:35.993562Z","shell.execute_reply.started":"2023-05-15T00:09:35.963817Z","shell.execute_reply":"2023-05-15T00:09:35.992690Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"train_ds = create_tensorflow_dataset(train_data, 64)\nval_ds = create_tensorflow_dataset(val_data, 64)\ntest_ds = create_tensorflow_dataset(test_data, 64)","metadata":{"id":"Ie5nF3jML_ww","execution":{"iopub.status.busy":"2023-05-15T00:09:35.994945Z","iopub.execute_input":"2023-05-15T00:09:35.995301Z","iopub.status.idle":"2023-05-15T00:09:36.067528Z","shell.execute_reply.started":"2023-05-15T00:09:35.995271Z","shell.execute_reply":"2023-05-15T00:09:36.066672Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"train_ds","metadata":{"id":"EhHXBSozF6_l","colab":{"base_uri":"https://localhost:8080/"},"outputId":"59af8ad5-5d4e-4590-d348-abd3b14976dc","execution":{"iopub.status.busy":"2023-05-14T12:17:15.279535Z","iopub.execute_input":"2023-05-14T12:17:15.279872Z","iopub.status.idle":"2023-05-14T12:17:15.289642Z","shell.execute_reply.started":"2023-05-14T12:17:15.279841Z","shell.execute_reply":"2023-05-14T12:17:15.288604Z"},"trusted":true},"execution_count":54,"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"<PrefetchDataset element_spec=(TensorSpec(shape=(64, 53), dtype=tf.int32, name=None), TensorSpec(shape=(64, 51), dtype=tf.int32, name=None))>"},"metadata":{}}]},{"cell_type":"code","source":"eg_in, eg_de = next(iter(train_ds))","metadata":{"id":"GvuZ6V6kRd_A","execution":{"iopub.status.busy":"2023-05-15T00:10:51.442999Z","iopub.execute_input":"2023-05-15T00:10:51.443797Z","iopub.status.idle":"2023-05-15T00:10:51.557796Z","shell.execute_reply.started":"2023-05-15T00:10:51.443763Z","shell.execute_reply":"2023-05-15T00:10:51.556871Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"INPUT_VOCAB_SIZE = len(context_tokenizer.word_index) + 1\nTARGET_VOCAB_SIZE = len(target_tokenizer.word_index) + 1\nEMB_DIMS = 256 \nHIDDEN_DIMS = 1024\nINPUT_SEQ_SIZE = eg_in.shape[1] \nTARGET_SEQ_SIZE = eg_de.shape[1]","metadata":{"id":"hEK2uje_LngA","execution":{"iopub.status.busy":"2023-05-15T00:10:51.586869Z","iopub.execute_input":"2023-05-15T00:10:51.587174Z","iopub.status.idle":"2023-05-15T00:10:51.593784Z","shell.execute_reply.started":"2023-05-15T00:10:51.587147Z","shell.execute_reply":"2023-05-15T00:10:51.591182Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"y8z0sqmLUueD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Encoder(tf.keras.Model):\n    \"\"\"\n        this class, is used as for constructing the encoder of type lstm.\n        Methods:\n          __init__: constructor.\n          call: used to pass the input to get an output.\n          initialize_hidden_state: used to initialize the initial hidden state of encoder(h0).\n        Params:\n          vocab_size(dtype: int) Dimension of the vectorized input.\n          embedding_dim(dtype: int): number of hidden units in the embedding layer.\n          h;idden_units(dtype: int): Number of hidden units in the LSTM layer.\n          bt_size(dtype: int): Batch Size.\n    \"\"\"\n    def __init__(self, vocab_size: int, embedding_dim: int, hidden_units: int, bt_size: int):\n        super(Encoder, self).__init__()\n        self.bt_size = bt_size\n        self.hidden_units = hidden_units\n        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim, name=\"embedding_layr\")\n        self.rnn = tf.keras.layers.GRU(self.hidden_units,\n                                       return_sequences=True, \n                                       return_state=True, \n                                       recurrent_initializer='glorot_uniform',\n                                       name=\"lstm_layer\"\n                                      )\n\n    def call(self, x, hidden):\n        x = self.embedding(x)\n        output, state = self.rnn(x, hidden)\n        return output, state\n\n    def initialize_hidden_state(self):\n        return tf.zeros((self.bt_size, 1024))","metadata":{"execution":{"iopub.status.busy":"2023-05-15T00:11:02.838144Z","iopub.execute_input":"2023-05-15T00:11:02.838604Z","iopub.status.idle":"2023-05-15T00:11:02.854082Z","shell.execute_reply.started":"2023-05-15T00:11:02.838573Z","shell.execute_reply":"2023-05-15T00:11:02.851839Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"class DotProductAttention(tf.keras.layers.Layer):\n    \"\"\"\n        this class is the custom keras layer for the dot product attention.\n        Methods:\n            call(scope: public): for calling the dotproduct attention.\n    \"\"\"\n    def call(self, query, values):\n        query_with_time_axis = tf.expand_dims(query, 1)\n\n        score = query_with_time_axis * values\n        score = tf.reduce_sum(score, axis=2)\n        score = tf.expand_dims(score, 2)\n\n        attention_weights = tf.nn.softmax(score, axis=1)\n\n        context_vector = attention_weights * values\n        context_vector = tf.reduce_sum(context_vector, axis=1)\n\n        return context_vector, attention_weights","metadata":{"execution":{"iopub.status.busy":"2023-05-15T00:09:38.577346Z","iopub.execute_input":"2023-05-15T00:09:38.577969Z","iopub.status.idle":"2023-05-15T00:09:38.585212Z","shell.execute_reply.started":"2023-05-15T00:09:38.577939Z","shell.execute_reply":"2023-05-15T00:09:38.584277Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"\nclass BahdanauAttention(tf.keras.layers.Layer):\n    \"\"\"\n        this class is the custom keras layer for the BahdanauAttention.\n        Methods:\n            call(scope: public): for calling the dotproduct attention.\n    \"\"\"\n    def __init__(self, units):\n        super(BahdanauAttention, self).__init__()\n        self.W1 = tf.keras.layers.Dense(units)\n        self.W2 = tf.keras.layers.Dense(units)\n        self.V = tf.keras.layers.Dense(1)\n\n    def call(self, query, values):\n\n        query_with_time_axis = tf.expand_dims(query, 1)\n        score = self.V(tf.nn.tanh(\n            self.W1(values) + self.W2(query_with_time_axis)))\n\n        attention_weights = tf.nn.softmax(score, axis=1)\n\n        context_vector = attention_weights * values\n        context_vector = tf.reduce_sum(context_vector, axis=1)\n\n        return context_vector, attention_weights\n     ","metadata":{"execution":{"iopub.status.busy":"2023-05-15T00:09:39.047276Z","iopub.execute_input":"2023-05-15T00:09:39.048803Z","iopub.status.idle":"2023-05-15T00:09:39.057063Z","shell.execute_reply.started":"2023-05-15T00:09:39.048762Z","shell.execute_reply":"2023-05-15T00:09:39.055635Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"\nclass DecoderWithAttention(tf.keras.Model):\n    \"\"\"\n        this class, is used as for constructing the decoder of type lstm.\n        Methods:\n            __init__: constructor.\n            call                      : used to pass the input to get an output.\n            initialize_hidden_state   : used to initialize the initial hidden state of encoder(h0).\n        Params:\n            vocab_size(dtype: int)               : Dimension of the vectorized input.\n            embedding_dim(dtype: int)            : number of hidden units in the embedding layer.\n            h;idden_units(dtype: int)            : Number of hidden units in the LSTM layer.\n            bt_size(dtype: int)                  : Batch Size.\n            attention_layer(type: keras.LAyer)   : Attention layer for the decoder.\n    \"\"\"\n    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz, attention_layer = None):\n        super(DecoderWithAttention, self).__init__()\n        self.batch_sz = batch_sz\n        self.dec_units = dec_units\n        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n        self.gru = tf.keras.layers.GRU(self.dec_units,\n                                       return_sequences=True,\n                                       return_state=True,\n                                       recurrent_initializer='glorot_uniform')\n        self.fc = tf.keras.layers.Dense(vocab_size)\n\n        self.attention = attention_layer\n\n    def call(self, x, hidden, enc_output):\n        x = self.embedding(x)\n        attention_weights = None\n\n        if self.attention:\n            context_vector, attention_weights = self.attention(hidden, enc_output)\n            x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n\n        output, state = self.gru(x, initial_state = hidden)\n\n        output = tf.reshape(output, (-1, output.shape[2]))\n        x = self.fc(output)\n\n        return x, state, attention_weights\n","metadata":{"execution":{"iopub.status.busy":"2023-05-15T00:09:40.117480Z","iopub.execute_input":"2023-05-15T00:09:40.118175Z","iopub.status.idle":"2023-05-15T00:09:40.128447Z","shell.execute_reply.started":"2023-05-15T00:09:40.118115Z","shell.execute_reply":"2023-05-15T00:09:40.127183Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def train_step(inp, targ, encoder,\n                       decoder, input_tok, \n                       target_tok, batch_size, optimizer):\n    \"\"\"\n        this function is a custom training step, which will use the TapeGradient to update the \n        parameter of the model.\n        Params:\n            inp(type: tf.Tensor)                : input for the model(vector of spanish words).\n            targ(type: tf.Tensor)               : target for the model(vector of english words).\n            encoder(keras.Model)                : keras model for the encoder part in seq2seq.\n            decoder(keras.Model)                : keras model for the decoder part in seq2seq.\n            input_tok(type; Dict)               :  Dict of words and their integer values for input.\n            target_tok(type: List)              : Dict of words and their integer values for target.\n            batch_size(dtype: int)              : Batch size.\n            optimizedr(type: keras.Optimizer)   : optimizer, that is used to update the parameter.\n        Return(dtype; float)\n            returns the loss valye, which is calculated.\n    \"\"\"\n    loss = 0\n    enc_hidden = encoder.initialize_hidden_state()\n    with tf.GradientTape() as tape: \n        enc_output, enc_hidden = encoder(inp, enc_hidden)\n        dec_hidden = enc_hidden\n        dec_input = tf.expand_dims([target_tok.word_index[\"<start>\"]] * batch_size, 1)\n\n        for t in range(1, targ.shape[1]):\n            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n\n            loss += loss_function(targ[:, t], predictions)\n\n            dec_input = tf.expand_dims(targ[:, t], 1)\n\n        batch_loss = (loss / int(targ.shape[1]))\n    variables = encoder.trainable_variables + decoder.trainable_variables\n    gradients = tape.gradient(loss, variables)\n    optimizer.apply_gradients(zip(gradients, variables))\n    return batch_loss\n\n\ndef test_step(inp, targ, encoder,\n                      decoder, input_tok, target_tok, batch_size):\n     \"\"\"\n        this function is a custom training step, which will use the TapeGradient to update the \n        parameter of the model.\n        Params:\n            inp(type: tf.Tensor)    : input for the model(vector of spanish words).\n            targ(type: tf.Tensor)   : target for the model(vector of english words).\n            encoder(keras.Model)    : keras model for the encoder part in seq2seq.\n            decoder(keras.Model)    : keras model for the decoder part in seq2seq.\n            input_tok(type; Dict)   : Dict of words and their integer values for input.\n            target_tok(type: List)  : Dict of words and their integer values for target.\n            batch_size(dtype: int)  : Batch size.\n        Return(dtype; float)\n            returns the loss valye, which is calculated.\n    \"\"\"\n    enc_hidden = encoder.initialize_hidden_state()\n    loss = 0\n    enc_output, enc_hidden = encoder(inp, enc_hidden)\n    dec_hidden = enc_hidden\n    dec_input = tf.expand_dims([target_tok.word_index[\"<start>\"]] * batch_size, 1)\n\n    for t in range(1, targ.shape[1]):\n        predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n        loss += loss_function(targ[:, t], predictions)\n        dec_input = tf.expand_dims(targ[:, t], 1)\n\n    loss = loss / int(targ.shape[1])\n    return loss","metadata":{"execution":{"iopub.status.busy":"2023-05-15T00:09:47.785155Z","iopub.execute_input":"2023-05-15T00:09:47.785643Z","iopub.status.idle":"2023-05-15T00:09:47.800614Z","shell.execute_reply.started":"2023-05-15T00:09:47.785607Z","shell.execute_reply":"2023-05-15T00:09:47.799645Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n\ndef loss_function(real, pred):\n    \"\"\"\n        this function, used to calculate the loss.\n        Params:\n            real(type: tf.Tensor) : ground truth.\n            pred(type: tf.Tensor) : predicted value from the model\n        Return(dtype: float)\n            returns the calcuated loss value.\n    \"\"\"\n    mask = tf.math.logical_not(tf.math.equal(real, 0)) \n    loss_ = loss_object(real, pred)\n    mask = tf.cast(mask, dtype=loss_.dtype)\n    loss_ *= mask\n    return tf.reduce_mean(loss_)","metadata":{"execution":{"iopub.status.busy":"2023-05-15T00:09:51.272644Z","iopub.execute_input":"2023-05-15T00:09:51.273349Z","iopub.status.idle":"2023-05-15T00:09:51.283876Z","shell.execute_reply.started":"2023-05-15T00:09:51.273305Z","shell.execute_reply":"2023-05-15T00:09:51.282919Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"import time\ndef training_seq2seq(encoder, decoder, train_dataset,\n                        val_dataset, optimizer,\n                        input_tok, target_tok,\n                        epochs, batch_size):\n    \"\"\"\n        this function used to do the manual training of the seq2seq model. with the help of train_step\n        and test_step functions.\n        Params:\n            encoder(keras.Model)                  : keras model for the encoder part in seq2seq.\n            decoder(keras.Model)                  : keras model for the decoder part in seq2seq.\n            train_dataset(type: tf.data.DAtaset)  : Training dataset.\n            train_dataset(type: tf.data.DAtaset)  : Validation dataset.\n            input_tok(type; tf.Tensor)            : tensor of words and their integer values for input.\n            target_tok(type: tf.Tensor)           : tensor of words and their integer values for target.\n            epochs(type: int)                     : Number of epochs.\n            batch_size(dtype: int)                : Batch size.\n            optimizer(tf.keras.Optimizer)         : Optimizer, used by the train_step function.\n        Return(keras.Model, keras.model, List, List)\n            returns the trained encoder, decoder and list of training and validation loss.\n    \"\"\"\n    training_loss = []\n    validation_loss = []\n\n    for epoch in range(epochs):\n        start = time.time()\n        total_loss = 0\n        total_loss_val =- 0\n\n        for (batch, (inp, targ)) in enumerate(tqdm.tqdm(train_dataset)):\n            batch_loss = train_step(inp, targ, \n                                    encoder, decoder, input_tok,\n                                    target_tok, batch_size, optimizer)\n\n            total_loss += batch_loss.numpy()\n\n        for (batch, (inp, targ)) in enumerate((val_dataset)):\n            batch_loss = test_step(inp, targ,\n                                     encoder, decoder, input_tok,\n                                     target_tok, batch_size)\n\n            total_loss_val += batch_loss.numpy()\n        \n        avg_train_loss = total_loss/float(len(train_dataset))\n        avg_val_loss = total_loss_val/float(len(val_dataset))\n        print(f\"Epoch {epoch} train_loss: {avg_train_loss} val_loss: {avg_val_loss}\")\n        training_loss.append(avg_train_loss)\n        validation_loss.append(avg_train_loss)\n\n    return encoder, decoder, training_loss, validation_loss","metadata":{"execution":{"iopub.status.busy":"2023-05-15T00:09:53.254823Z","iopub.execute_input":"2023-05-15T00:09:53.255743Z","iopub.status.idle":"2023-05-15T00:09:53.268196Z","shell.execute_reply.started":"2023-05-15T00:09:53.255705Z","shell.execute_reply":"2023-05-15T00:09:53.267154Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Dot Prodcut Attention.\noptimizer = tf.keras.optimizers.Adam()\nattention = DotProductAttention()\nencoder = Encoder(INPUT_VOCAB_SIZE, EMB_DIMS, HIDDEN_DIMS, 64)\ndecoder = DecoderWithAttention(TARGET_VOCAB_SIZE, EMB_DIMS, HIDDEN_DIMS, 64, attention)\nencoder_t, decoder_t, training_loss, validation_loss = training_seq2seq(encoder, decoder, \n                            train_ds, val_ds, optimizer, context_tokenizer, target_tokenizer, 3, 64)\n\nencoder_t.save(\"seq_seq_gru_attention_encoder\")\ndecoder_t.save(\"seq_seq_gru-attention_decoder\")","metadata":{"execution":{"iopub.status.busy":"2023-05-14T14:31:12.051092Z","iopub.execute_input":"2023-05-14T14:31:12.051440Z","iopub.status.idle":"2023-05-14T15:59:15.887339Z","shell.execute_reply.started":"2023-05-14T14:31:12.051412Z","shell.execute_reply":"2023-05-14T15:59:15.886283Z"},"trusted":true},"execution_count":137,"outputs":[{"name":"stderr","text":"100%|██████████| 1487/1487 [27:39<00:00,  1.12s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 0 train_loss: 0.7499041346471103 val_loss: 0.6028971610842524\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1487/1487 [27:32<00:00,  1.11s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 train_loss: 0.49198000923690977 val_loss: 0.3939233282127896\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1487/1487 [27:49<00:00,  1.12s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 train_loss: 0.30766756600113465 val_loss: 0.29631480703482754\n","output_type":"stream"}]},{"cell_type":"code","source":"# Dot Prodcut Attention.\noptimizer = tf.keras.optimizers.Adam()\nattention = BahdanauAttention(256)\nencoder = Encoder(INPUT_VOCAB_SIZE, EMB_DIMS, HIDDEN_DIMS, 64)\ndecoder = DecoderWithAttention(TARGET_VOCAB_SIZE, EMB_DIMS, HIDDEN_DIMS, 64, attention)\nencoder_t, decoder_t, training_loss, validation_loss = training_seq2seq(encoder, decoder, \n                            train_ds, val_ds, optimizer, context_tokenizer, target_tokenizer, 3, 64)\n\nencoder_t.save(\"seq_seq_gru_attention_bahdanadu_encoder\")\ndecoder_t.save(\"seq_seq_gru-attention_bahdanadu_decoder\")","metadata":{"execution":{"iopub.status.busy":"2023-05-15T00:11:17.137563Z","iopub.execute_input":"2023-05-15T00:11:17.137972Z","iopub.status.idle":"2023-05-15T01:56:31.934774Z","shell.execute_reply.started":"2023-05-15T00:11:17.137937Z","shell.execute_reply":"2023-05-15T01:56:31.933807Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stderr","text":"100%|██████████| 1487/1487 [32:39<00:00,  1.32s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 0 train_loss: 0.6406364146702708 val_loss: 0.3980408955264736\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1487/1487 [33:21<00:00,  1.35s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 train_loss: 0.29456486556461053 val_loss: 0.2674178850811881\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1487/1487 [32:56<00:00,  1.33s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 train_loss: 0.1738644652895344 val_loss: 0.24044849051011574\n","output_type":"stream"}]},{"cell_type":"code","source":"def translate(sentence, encoder, decoder):\n    \"\"\"\n        this function, used to infer the trained model.\n        Params:\n            sentence(dtype: str)   : sentence, that needed to be transalated.\n            encoder(keras.Model)   : Keras model of the encoder trained.\n            decoder(keeras.Model)  : Keras model of the decoder trained.\n        \n        Returns(dtype: str, str)\n            returns the translated value of spanish to english and the spanish sentence.\n    \"\"\"\n    attention_plot = np.zeros((51, 53))\n\n    sentence = preprocess_sentence(sentence)\n\n    inputs = [context_tokenizer.word_index[i] for i in sentence.split(' ')]\n    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n                                                         maxlen=51,\n                                                         padding='post')\n    inputs = tf.convert_to_tensor(inputs)\n\n    result = ''\n\n    hidden = [tf.zeros((1, 1024))]\n    enc_out, enc_hidden = encoder(inputs, hidden)\n\n    dec_hidden = enc_hidden\n    dec_input = tf.expand_dims([target_tokenizer.word_index['<start>']], 0)\n\n    for t in range(51):\n        predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_out)\n\n        predicted_id = tf.argmax(predictions[0]).numpy()\n        \n        if not target_tokenizer.index_word[predicted_id] == \"<end>\": \n            result += target_tokenizer.index_word[predicted_id] + ' '\n\n        if target_tokenizer.index_word[predicted_id] == '<end>':\n            return result, sentence\n        dec_input = tf.expand_dims([predicted_id], 0)\n\n    return result, sentence\n     ","metadata":{"execution":{"iopub.status.busy":"2023-05-15T02:06:04.349953Z","iopub.execute_input":"2023-05-15T02:06:04.350331Z","iopub.status.idle":"2023-05-15T02:06:04.360589Z","shell.execute_reply.started":"2023-05-15T02:06:04.350302Z","shell.execute_reply":"2023-05-15T02:06:04.359592Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"translate(u'¿todavia estan en casa?', encoder_t, decoder_t)","metadata":{"execution":{"iopub.status.busy":"2023-05-15T02:13:38.608818Z","iopub.execute_input":"2023-05-15T02:13:38.609196Z","iopub.status.idle":"2023-05-15T02:13:38.712994Z","shell.execute_reply.started":"2023-05-15T02:13:38.609165Z","shell.execute_reply":"2023-05-15T02:13:38.712038Z"},"trusted":true},"execution_count":85,"outputs":[{"execution_count":85,"output_type":"execute_result","data":{"text/plain":"('are you still at home ? ', '<start> ¿ todavia estan en casa ? <end>')"},"metadata":{}}]}]}